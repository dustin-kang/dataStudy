# Feature Scaling
> 데이터를 가진 **feature의 크기가 심하게 차이나는 경우**, 모든 데이터가 **동일한 단위로 맞추기 위해** 정규화를 진행합니다.

<img width="677" alt="image" src="https://user-images.githubusercontent.com/55238671/210356646-f41545a0-8edd-4601-bf02-6306e48a9ebc.png">


### 최소 - 최대 정규화 (Mix-Max Normalization)
> 각 Feature의 최소값을 0, 최대값을 1로 두고 변환하는 방법입니다.
> $$\frac{x-\min}{\max-\min}$$

<img src="https://user-images.githubusercontent.com/55238671/210356484-825565da-7dd5-4ff3-9e26-c99754151962.png" width=500>

```py
# 함수 형식
def min_max_normalize(lat):
    normalized = []

    for value in lat:
        normalizard_num = (value - min(lat)) / (max(lat) - min(lat))
        normalized.append(normalized_num)

    return normalized

# Sklearn
from sklearn.preprocessing import MinmaxScaler

scaler = MinmaxScaler()
train_scaled = scaler.fit_transform(X_train)
test_scaled = scaler.transform(X_test)


```
- 단점 : **이상치(Outlier)의 영향을 많이 받는다**는 것입니다. (이러한 경우, Z- 점수 정규화로 보완해야 한다. 또는 `RobustSclaer`를 사용하여 최소한으로 줄인다.)
- 학습 데이터를 기반으로 학습이 되기 때문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 합니다.
- [🔗 `MinMaxScaler` 사이킷런 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)

### Z- 점수 표준화 (Z- Score Normalization)
> - **이상치(Outlier) 문제를 피하기 위해** X라는 값을 Z-점수로 바꿔주는 식이다.
> - 평균이 0이고 분산 1인 값으로 변환하여 가우시안 정규분포를 따르도록 변환한다. 
> 
> $$ \frac{x-\mu}{\sigma} \\ \text{x - mean / std}  $$

<img src="https://user-images.githubusercontent.com/55238671/210356557-a32ff9e0-adf5-4dd8-b86b-d8875424451c.png" width=500>

```py
# 함수 형식
def z_score_normalization(lat):
    normalizated = []

    for value in lat:
        normalized_num  = (value - np.mean(lat)) / np.std(lat)
        normalized.append(normalized_num)

    return normalized

# Sklearn
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
train_scaled = scaler.fit_transform(X_train)
test_scaled = scaler.transform(X_test)
```
- 정확히 동일한 척도로 정규화된 데이터를 생성하지 않는다. 
- [🔗 `StandardScaler` 사이킷런 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)

[🔗 정규화 쉽게 이해하기 - 아무튼 워라밸](https://hleecaster.com/ml-normalization-concept/)
[🔗 정규화의 목적과 방법들 - 발보는 두더지](https://mole-starseeker.tistory.com/31)

> 🙋‍♂️ 추가적으로 배우게될 라쏘회귀와 릿지 회귀는 선형 회귀 파트에서 배우게 됩니다. 


# 📌 통계학 간단 정리
> 대표값(Reprensentative Value)
- 어떤 데이터를 대표하는 하나의 값을 의미합니다.
- 평균, 총점, 중앙값, 최빈값등 기준에 따라 다르게 정해집니다.

> 평균(Mean)
- 평균의 종류로 산술평균, 기하평균, 조화평균이 있는데 가장 기본적으로 사용하는 평균이 산술평균입니다.

> 분산(Variance)
- 데이터들이 얼마나 많이 퍼져 있는가를 나타냅니다.
- 편차(Deviation)들의 제곱의 평균을 분산이라고 합니다.

> 표준편차(Standard Deviation)
- 분산의 제곱근을 의미합니다.
- 데이터들 간의 퍼진 정도(간격)을 의미합니다. 

> 정규화와 표준화
- 정규화 : 데이터 값들을 공통된 간격으로 데이터를 늘이거나 줄이는 방법
- 표준화 : 데이터 값들을 공통된 척도로 데이터를 다시 줄세우는 방법


[🔗 toyourlight 블로그](https://toyourlight.tistory.com/36)
