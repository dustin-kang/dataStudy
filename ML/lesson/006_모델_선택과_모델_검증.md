# 모델 선택
> 🔍 **좋은 모델은 무엇일까?**
> - **데이터의 패턴**을 잘 학습한 모델
> - 한번도 본 적 없는 데이터에 대해 옳은 판단을 내리는 모델
> - **모델의 일반화**가 이루어져 적정한 수준의 성능을 보이는 모델


[🔗 모델 학습 방법과 일반화 성능 - 인생의 굴레에서1](https://dragsoseumon.tistory.com/34)

## 모델의 기준
> - 머신러닝 모델을 선택할 때 `사용 목적`을 기준으로 두어야합니다. (예측인 경우, 수치, 분류인 경우는 라벨)




### 기준 모델 (Baseline Model)
> - 기준 모델은 가정을 위해 만들어지는 모델로 단순 비교를 위함입니다.

- 분류 문제 : 타깃값의 **최빈 클래스**를 기준 모델로 정합니다.
- 회귀 문제 : 타깃값의 **평균값**을 기준 모델로 정합니다.
- 회귀 시계열 문제 : **이전 타임 스탬프 값**을 기준 모델로 정합니다.


## 모델의 성능을 높이는 방법
> 모델의 정확도와 성능을 높이기 위해 **하이퍼파라미터(Hyper Parameter)** 를 사용합니다.

### 하이퍼 파라미터(Hyper Parameter)
- 사용자가 스스로 값을 조절하여 일반화 성능을 높이는 것.
- _e.g. Learning rate, Epoch, K Value, tree depth etc._

### 파라미터 (Parameter)
- 기계에서 정한 값
- _e.g. 기울기(`coef_`), 절편(`intercept_`)

# 모델 검증

> 최종 결과 예측 전, 모델의 성능을 평가하기 위해 검증 데이터셋을 이용하는데 이를 여러번 교체하면서 평가하는 작업을 **교차 검증(Cross Validation)** 이라고 합니다.

## 교차검증
|-|장점|단점|예시|
|:---|:---|:---|:---|
||적은 데이터에 대한 Validation  신뢰성을 높일 수 있고 더 일반화된 모델을 만들 수 있다.|모델 학습의 오랜 시간이 소요된다.|홀드 아웃, K-겹, 계층별 K-겹|

> 🔍 적은 데이터셋으로 훈련/테스트로 나눠버리게 되면 과대적합이나 이상치 문제로 부정확한 성능을 낼 수 있기 때문에 교차검증을 사용합니다.


### K-겹 교차검증(K-fold Cross Validation)
> 훈련 데이터를 K개의 fold로 나눈다음, 그 중 하나의 fold를 검증 데이터셋으로 삼아 **k번 반복하여 검증**하여, 그 평균의 결과를 사용하는 방법입니다.

- **랜덤**으로 검증 데이터셋이 지정됩니다. 
- 결과적으로 **편향된 데이터가 생긴다는 단점**이 있고 이를 해결하기위해 계층별 K-겹 교차검증이  등장했습니다.


```py
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

# Kfold 객체를 추가하여 상세 조정할 수 있습니다.
kfold = KFold(n_splits=6, shuffle= True, random_state=0)

scores = cross_val_score(모델 객체, 훈련 데이터의 feature, 훈련 데이터의 Target, cv=kfold)

print('교차 검증별 정확도:',np.round(scores, 4))
print('평균 검증 정확도:', np.round(np.mean(scores), 4))
```
- `n_split` : 몇개로 분할 할지 갯수 선정
- `shuffle` : Fold 나누기 전에 무작위 섞을지 불린
- `random_state` : 나눈 fold를 그대로 사용할지



### 계층별 K-겹 교차검증 (Stratified K-Fold Validation)
> 기존의 교차검증과 다르게 랜덤으로 검증 데이터셋(fold)을 지정하는 게 아니라 **각 클래스 별 비율을 고려**하여 검증 데이터셋을 구성합니다.

### 홀드 아웃 교차검증(Holdout Cross Validation)
> 일정한 비율의 **검증 데이터셋을 하나 지정**하여 사용하는 방식입니다.

- 교체를 하지않아 검증 데이터셋이 훈련 데이터셋으로 사용하지 않습니다.
- 검증 데이터셋이 편향되도록 모델을 조정하게됩니다. 
- 이 문제를 해결하기 위해 K-겹 교차검증이 등장했습니다.

> **🔍 데이터 양이 많을 수록 K 값은 줄어야 합니다.**
> 만약 K=20일 경우 데이터수가 증가하기 떄문에  분산이 증가한다고 생각할 수 있지만 20개에서 평균을 내기 때문에 1/20으로 압축하는 꼴입니다. 오히려 분산이 내려가게 됩니다. 



[🔗 머신 러닝의 모델 평가와 모델 선택, 알고리즘 선택 – 1장. 기초 - 텐서플로우 블로그](https://tensorflow.blog/머신-러닝의-모델-평가와-모델-선택-알고리즘-선택-1/) <br> [🔗 [ML] 교차검증 (CV, Cross Validation) 이란? - 우노](https://wooono.tistory.com/105) <br> [🔗 [머신러닝 배우기] 3.머신러닝의 주요 개념 - 모델 - Aiden](https://isme2n.github.io/devlog/2017/10/27/machine-learning-3/)