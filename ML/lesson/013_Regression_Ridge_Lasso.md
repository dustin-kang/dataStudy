# ë¦¿ì§€íšŒê·€ ë¼ì˜ íšŒê·€
[ì •ê·œí™”](https://github.com/dustin-kang/dataStudy/blob/main/ML/lesson/007_ëª¨ë¸_í‰ê°€ì™€_ëª¨ë¸_ê°œì„ .md#ì¼ë°˜í™”generalization)ì˜ ëª©ì ì€ ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì— Overfitting ë˜ì§€ ì•Šê³  ì²˜ìŒ ë³´ëŠ” í…ŒìŠ¤íŠ¸ - ë°ì´í„°ì—ë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë–„ loss í•¨ìˆ˜ì— `L1, L2 í•­`ì„  ì¶”ê°€í•˜ê²Œë˜ë©´ **ê¸°ì¡´ì˜ lossë„ ì¤„ì´ë©´ì„œ ì •ê·œí™” í•­ë„ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ**ë©ë‹ˆë‹¤. 

> ğŸ’¡ ëª¨ë¸ì˜ **í”¼ì³ê°’ì´ ì¤„ì–´ë“¦ì— ë”°ë¼** íŠ¹ì • í”¼ì³ê°€ ë„ˆë¬´ í° ê°’ì„ ê°–ì§€ ì•Šê²Œ ë˜ë©´ì„œ ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. (íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•˜ì—¬ íšŒê·€ê³„ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ê²ƒì…ë‹ˆë‹¤.)


ëŒë‹¤ ê°’ì´ ì¦ê°€í•  ìˆ˜ë¡ íšŒê·€ ê³„ìˆ˜ë“¤ì€ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ê²Œ ë˜ëŠ”ë° ì´ëŸ¬ë©´ **ì ì  ë³µì¡í•œ ëª¨ë¸ì—ì„œ ë‹¨ìˆœí•œ ëª¨ë¸ì´ ë©ë‹ˆë‹¤**. (ë‹¨ìˆœí•œ ëª¨ë¸ì´ë¼ëŠ” ê²ƒì€ í¸í–¥ì„ ì¦ê°€í•˜ì—¬ ë¶„ì‚°ì„ ì¤„ì´ê¸° ë•Œë¬¸ì— ê¸°ìš¸ê¸°ê°€ ì¤„ì–´ë“œëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.) 

## Lasso (L1 ì •ê·œí™”), LAE

$$ L1Loss = \sum^n_{i=1} |y_i - f(x_i)| $$

- íŠ¹ì • Featureì˜ ê°’ì´ ë§¤ìš° ë‚®ì€ ê²½ìš°(= Outlier) **0ì´ ë˜ëŠ” íŠ¹ì§•**ì´ ìˆìŠµë‹ˆë‹¤.
- ì¦‰, 0ì— ìˆ˜ë ´í•˜ëŠ” ê²½ìš°ëŠ” [Feature Selection](https://github.com/dustin-kang/dataStudy/blob/main/ML/lesson/010_ë°ì´í„°_ì „ì²˜ë¦¬ì™€_íŠ¹ì„±ì„ íƒ.md#embedded-method)ê³¼ ë™ì¼í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì¥ë‹¨ì 

- L1 Lossê°€ 0ì¸ ì§€ì ì—ì„œëŠ” ë¯¸ë¶„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
- ì´ìƒì¹˜(Outlier)ì— ëŒ€í•´ L2 ë³´ë‹¤ ëœ ë¯¼ê°í•©ë‹ˆë‹¤. (Robust)

## Ridge (L2 ì •ê·œí™”), LSE

$$ L2Loss = \sum^n_{i=1} (y_i - f(x_i))^2 $$

- 0ì— ìˆ˜ë ´ê¹Œì§„ í•˜ì§€ ì•Šê³ , ê°€ì¤‘ì¹˜ë“¤ì´ **0ì— ê°€ê¹ê²Œ í•˜ëŠ” íŠ¹ì§•(ìˆ˜ë ´)** ì´ ìˆìŠµë‹ˆë‹¤. 
- L1 ì •ê·œí™”ì— ë¹„í•´ ê°•í•˜ì§€ ì•Šê²Œ ì •ê·œí™”ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„ í˜•ëª¨ë¸ì— ì¼ë°˜í™” íš¨ê³¼ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì¥ë‹¨ì 


- ì´ìƒì¹˜(Outlier)ì— ëŒ€í•´ ë¯¼ê°í•©ë‹ˆë‹¤. ìµœì†Œì œê³±ë²• ì•„ì‹œì£ ? (Not very Robust)

[ğŸ’» Ridge íšŒê·€ ì‹¤ìŠµ]()

## ElasticNet

- L1ì™€ L2ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì ˆí•˜ì—¬ ë§Œë“­ë‹ˆë‹¤. 
- ë¼ì˜(Lasso)ì™€ ë¦¿ì§€(Ridge)ì˜ ìµœì í™” ì§€ì ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— **ë‘ ì •ê·œí™” í•­ì„ í•©ì³ì„œ** **rë¡œ ê·œì œ ì •ë„ë¥¼ ì¡°ì ˆ**í•©ë‹ˆë‹¤.

> ### Norm?
> Normì€ ë²¡í„°ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒìœ¼ë¡œ **L1ì€ ì ˆëŒ“ê°’ì˜ í¬ê¸°, L2ëŠ” ì§ì„  ê±°ë¦¬(ì œê³±ì˜ ë£¨íŠ¸)** ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.



## Reference
- [ğŸ”— ë”¥ëŸ¬ë‹ ìš©ì–´ ì •ë¦¬, L1 Regularization, L2 Regularization ì˜ ì´í•´, ìš©ë„ì™€ ì°¨ì´ ì„¤ëª… - ë¹›ë‚˜ëŠ” ë‚˜ë¬´](https://light-tree.tistory.com/125)
- [ğŸ”— ë¦¿ì§€íšŒê·€, ë¼ì˜íšŒê·€, ì—˜ë¼ìŠ¤í‹±ë„· - ëŒ€í•™ì›ìƒì´ ì‰½ê²Œ ì„¤ëª…í•´ë³´ê¸°](https://hwiyong.tistory.com/93)
- [ğŸ”— L1, L2 Norm, Loss, Regularization? - ìƒê° ì •ë¦¬](https://junklee.tistory.com/29)
- [ğŸ“¼ Regularization Part 1: Ridge (L2) Regression - StatQuest](https://youtu.be/Q81RR3yKn30?t=635)
- [ğŸ”— Sklearn RidgeCV ê³µì‹ë„íë¨¼íŠ¸ ](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)
- [ğŸ”— Sklearn Ridge ê³µì‹ë„íë¨¼íŠ¸ ](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)
