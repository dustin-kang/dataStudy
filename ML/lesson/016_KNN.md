# KNN 알고리즘

- 가까운 기리 함꼐 모이는 알고리즘으로 거리기반 분류 분석 모델 알고리즘임. Y(클래스)가 존재하므로 클러스터링이랑은 다름.
- 유클리디안 거리 게산 사용
- 얼굴인식, 글자 인식, 추천 등에 대해 사용됨
- K의 갯수는 홀수가 좋다 : 동점 발생

- 장점 :  간단 구현, 데이터 분포를 가정하지 않음, 수치기반 분류에 성능이 우수, 이중분류나 다중분류에 적용 가능, 사전 학습필요 없음
- 단점 : 모델을 생성하지 않아 특징과 클래스 관계 이해에 어려움, 데이터가 많아지면 분류가 느림

- 거리 기반이므로 표준화가 필요
- 알고리즘 구현시, MinMax 나 z-score로 재조정 가능

- 적절한 K 값을 설정해주는 것이 중요합니다.

```py
from sklearn.neighbors import KNeighborsClassifier 
kn = KNeighborsClassifier(n_neighbors=49) # 몇개의 최근접을 조사하여 데이터 분류를 할지 지정하는 옵션

kn.fit(fish_data, fish_target) 
print(kn.score(fish_data, fish_target)) # 1.0
```
- `kn.kneighbor([])` : 주어진 샘플에서 가장 가까운 이웃을 찾는다., 이웃까지의 거리와 이웃 샘플인덱스를 반환 

> - [KNN 개념 정리 및 활용 (sklearn)](https://ineed-coffee.github.io/posts/KNN/)