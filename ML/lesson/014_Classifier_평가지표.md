# ë¶„ë¥˜ (Classifier)
ë¶„ë¥˜ ëª¨ë¸ì€ **ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ ë³„ë¡œ ë‚˜ëˆ„ëŠ” ëª¨ë¸**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ëª…í™•í•˜ê²Œ ì„ ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” **ì„ í˜• ëª¨ë¸**ë¡œëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€(Rogistic Regression), ì„œí¬íŠ¸ ë²¡í„°ë¨¸ì‹ (SVM)ì´ ìˆìœ¼ë©° ë¶ˆê·œì¹™í•˜ê²Œ í©ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ì„œ(**ë¹„ì„ í˜• ëª¨ë¸**)ëŠ” ì»¤ë„ ì„œí¬íŠ¸ ë²¡í„°ë¨¸ì‹ ê³¼ ê²°ì •íŠ¸ë¦¬ kNN, ëœë¤í¬ë ˆìŠ¤íŠ¸ ë“±ì´ ìˆìŠµë‹ˆë‹¤.


> ### ğŸ’¡ ê¸°ì¤€ ëª¨ë¸ (Baseline Model)
> ëª¨ë“  ë°ì´í„°ê°€ í•­ìƒ ê· í˜•ëœ ë°ì´í„°ë¼ê³  ìƒê°í•˜ì‹œë©´ ì•ˆë©ë‹ˆë‹¤. ê°€ë” ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ íƒ€ê²Ÿ ê°’ì´ **í¸ì¤‘ë˜ì–´ ìˆëŠ” ê²½ìš°ê°€ ìˆê¸° ë•Œë¬¸**ì— ì •í™•ë„ë¼ëŠ” ì§€í‘œë§Œìœ¼ë¡œ íŒë‹¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤. _ê°ì—¼ìì™€ ë¹„ê°ì—¼ì ë¹„ìœ¨ì´ 1:9ë‹ˆê¹Œ ì •í™•ë„ 90%ì´ë¼í•´ì„œ ì¢‹ì€ ì„±ëŠ¥ì´ë¼ê³  íŒë‹¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤._
> ê¸°ì¤€ ëª¨ë¸ì„ ì„¸ìš°ê³  ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì´ ë˜ê²Œë” ë…¸ë ¥í•´ì•¼í•©ë‹ˆë‹¤.
> - íšŒê·€ ë¬¸ì œ : í‰ê· ê°’ìœ¼ë¡œ ê¸°ì¤€ ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.
> - ë¶„ë¥˜ ë¬¸ì œ : ìµœëŒ€ ë¹ˆë„ ê°’ìœ¼ë¡œ ê¸°ì¤€ ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.
> - ì‹œê³„ì—´ ë¬¸ì œ : ì´ì „ ì‹œê°„ì˜ ë°ì´í„°ê°€ ê¸°ì¤€ ëª¨ë¸ì´ ë©ë‹ˆë‹¤. 
> 
> í´ë˜ìŠ¤ê°€ ë§ì€ ê²½ìš°ì—ë„ ì •í™•ë„ê°€ ë‚®ì•„ì§€ê¸° ë•Œë¬¸ì— **íšŒê·€ ë¬¸ì œ**ë¡œ í’€ì–´ì•¼í•©ë‹ˆë‹¤.
> [ğŸ’» ì‹¤ìŠµìë£Œ]()

## ì´ì§„ ë¶„ë¥˜ (Binary Classification)

$$ Log Loss = -(y-\log(p)) + (1-y)\log(1-p) $$

ì´ì§„ ë¶„ë¥˜ê¸°ì— ëŒ€í‘œì ì¸ ëª¨ë¸ë¡œëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ ì„œí¬íŠ¸ ë²¡í„°ë¨¸ì‹ ì´ ìˆìŠµë‹ˆë‹¤. ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¼ëŠ” ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 

### ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ (Sigmoid Function)
<img src="https://velog.velcdn.com/images%2Fmetterian%2Fpost%2Fee23f919-20f3-4acd-8110-b39a99df6096%2Fimage-20210413212222497.png" width = 400>



ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ”ë°ìš”. ê´€ì¸¡ê°’ì´ íŠ¹ì • í´ë˜ìŠ¤ì— ì†í•  í™•ë¥  ê°’ì„ ê³„ì‚°í•˜ê²Œ ë©ë‹ˆë‹¤. ë§Œì•½ í™•ë¥ ê°’ì´ ê¸°ì¤€ ê°’ë³´ë‹¤ í¬ë©´ 1 ì•„ë‹ˆë©´ 0ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê²Œ ë˜ëŠ” ê±°ì£ .

[ğŸ”— ë¡œì§€ìŠ¤í‹± íšŒê·€]()ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë‹¤ì¤‘ ë¶„ë¥˜ (Multiclass Classification)

$$ Categorical CrossEntropy = -\frac{1}{N}\sum_{i=1}^N\sum_{j=1}^My_{ij}*\log(p_{ij}) $$

ë‹¤ì¤‘ ë¶„ë¥˜ëŠ” ì…‹ ì´ìƒì˜ í´ë«ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ëŒ€í‘œì ì¸ ëª¨ë¸ë¡œ SGD ë¶„ë¥˜ê¸°, ëœë¤ í¬ë ˆìŠ¤íŠ¸, ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸° ë“±ì´ ìˆìŠµë‹ˆë‹¤. 

> ğŸ’¡ **ì´ì¤‘ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ë‹¤ì¤‘ ë¶„ë¥˜ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆëŠ”ë°ìš”.** ê·¸ ì „ëµë“¤ë¡œ ë‘ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. (ì´ì¤‘ë¶„ë¥˜ì—ì„œ ë‹¤ì¤‘ í´ë˜ìŠ¤ë¡œ í™•ì¥í•˜ëŠ” ë°©ë²•)

### OvR ì „ëµ (One-versus-the-Rest)
- OvA(One-versus-all)ì´ë¼ê³  í•˜ëŠ” ì´ ì•Œê³ ë¦¬ì¦˜ì€ ê°ê¸° ë‹¤ë¥¸ Nê°œì˜ ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ ì‹¤í–‰ í•œ í›„  Nê°œì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

### OvO ì „ëµ (One-versus-One)
- ê° ìˆ«ìì˜ ì¡°í•©ë§ˆë‹¤ ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ ì‹¤í–‰í•œ í›„ ê°€ì¥ ë§ì´ ì„ íƒëœ í´ë˜ìŠ¤ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
- $  N \text{í´ë˜ìŠ¤} = \frac{N *(N-1)}{2}  $

```py
# OVR, OVOë¥¼ ê°•ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
from sklearn.multiclass import OneVsRestClassifier
ovr_clf = OneVsRestClassifier(SVC())

```

> ë³´í†µ OvR ë°©ë²•ì„ ì„ í˜¸í•˜ì§€ë§Œ ì¼ë¶€ ì•Œê³ ë¦¬ì¦˜ì€ í›ˆë ¨ì„¸íŠ¸ì˜ í¬ê¸°ì— ë¯¼ê°í•˜ê¸° ë•Œë¬¸ì— ì‘ì€ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ë§ì€ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ”ê²Œ ë” ë¹ ë¥´ê¸° ë–„ë¬¸ì— OvO ì „ëµì„ ì„ í˜¸í•©ë‹ˆë‹¤. 

### ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ (Softmax Function)
- ì„¸ ê°œ ì´ìƒìœ¼ë¡œ ë¶„ë¥˜ë¥¼ í•˜ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜ì…ë‹ˆë‹¤.

$$softmax(z) = [\frac{e^{z1}}{e^{z1}+e^{z2}+e^{z3}}, \frac{e^{z2}}{e^{z1}+e^{z2}+e^{z3}}, \frac{e^{z3}}{e^{z1}+e^{z2}+e^{z3}}] = [p1,p2,p3]$$

> ì´ì™¸ì—ë„ ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ë˜ëŠ” ë‹¤ì¤‘ í’€ë ¥ ë¶„ë¥˜ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.
> - ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ : ì´ì§„ ë‹µì„ ë‹¤ì¤‘ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ë¶„ë¥˜ ì‹œìŠ¤í…œ _í™€ìˆ˜ì¸ì§€ ì§ìˆ˜ì¸ì§€ì™€ 8ë³´ë‹¤ ë†’ì€ ìˆ˜ ì¸ì§€ ë¶„ë¥˜
> - ë‹¤ì¤‘ ì¶œë ¥ ë¶„ë¥˜ : í•œ ë ˆì´ë¸”ì´ ì—¬ëŸ¬ í´ë˜ìŠ¤ê°€ ë  ìˆ˜ ìˆë„ë¡ ì¼ë°˜í™” í•œ ê²ƒ ì…ë‹ˆë‹¤. 
> ```py
> y_train_large = (y_train >= 7)
> y_train_odd = (y_train %2 == 1)
> y_multilabel = np.c[y_train_large, y_train_odd]
> knn_clf.fit(X_train, y_nultilabel)
>```

# í‰ê°€ ì§€í‘œ (Metrics)
- ë¶„ë¥˜ëª¨ë¸ì—ëŠ” ì •í™•ë„ ë§ê³ ë„ ë‹¤ë¥¸ í‰ê°€ì§€í‘œë“¤ì´ ìˆìŠµë‹ˆë‹¤.

### ì •í™•ë„(Accuracy)
$$ Accuracy = \frac{Same Predict}{Total Predict} $$
- ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ ì •í™•í•œì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. 
- ë¼ë²¨ì´ ë¶ˆê· í˜•í•œ ë°ì´í„°ì—ì„œëŠ” ì‚¬ìš©í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.

[ğŸ”— ì •í™•ë„ ê³µì‹ ë„íë¨¼íŠ¸ ](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)

### ì˜¤ì°¨ í–‰ë ¬ (Confusion Matrix)

- ìœ„ ë„í‘œ ì²˜ëŸ¼ ì£¼ë¡œ ì´ì§„ ë¶„ë¥˜ì—ì„œ ë§ì´ ì‚¬ìš©í•˜ë©° ëª¨ë¸ì´ ì–´ë–¤ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼°ëŠ”ì§€ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
from sklearn.metrics import plot_confusion_matrix, classification_report
print(classification_report(y_val, y_pred))

import matplitlib.pyplot as plt # ê·¸ë˜í”„ ëª¨ë“ˆ

fig, ax = plt.subplot()
pcm = plot_confusion_matrix(model,
        x_val, y_val,
        cmap = ply.cm.Reds # ì»¬ëŸ¬í…Œë§ˆ
        ax = ax # plotting í•  ì¢Œí‘œì¶• ê°ì²´

plt.title(f'í˜¼ë™í–‰ë ¬, n={len(y_val}', fontsize=16)
plt.show()

cm = pcm.confusion_matrix
cm
```

- [ğŸ”— Confusion Matrix ê³µì‹ ë„íë¨¼íŠ¸](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)

#### ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall)
- ì •ë°€ë„ëŠ” ì˜ˆì¸¡ì„ ê¸ì •ìœ¼ë¡œ í•œ ë°ì´í„° ì¤‘ì—ì„œ ì‹¤ì œë¡œ ê¸ì •ì¸ ë¹„ìœ¨ì„ ë§í•©ë‹ˆë‹¤.
- ì¬í˜„ìœ¨ì€ ì‹¤ì œë¡œ ê¸ì •ì¸ ë°ì´í„° ì¤‘ ì˜ˆì¸¡ì„ ê¸ì •ìœ¼ë¡œ í•œ ë¹„ìœ¨ì„ ë§í•©ë‹ˆë‹¤.
- ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì€ íŠ¸ë ˆì´ë“œ ì˜¤í”„`TradeOff` ê´€ê³„ë¥¼ ê°–ìŠµë‹ˆë‹¤. ê·¸ë˜ë„ ê°€ì¥ ì¢‹ì€ ê²½ìš°ëŠ” ë‘ ì§€í‘œê°€ ì ë‹¹íˆ ë†’ì„ ë•Œ ì¸ê±°ê² ì£ ?

### F1 Score

$$ F1 =  \frac{2}{\frac{1}{RECALL} + \frac{1}{PRECISION}} = 2 * \frac{PPV * TPR}{PPV + TPR} $$

- ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ í•œìª½ì— ì¹˜ìš°ì¹˜ì§€ ì•Šê³  ë‘˜ ë‹¤ **ê· í˜•ì„ ì´ë£¨ëŠ” ê²ƒ**ì„ `F1 Score`ë¼ê³  í•©ë‹ˆë‹¤. ë˜ëŠ” **ì¡°í™”í‰ê· (harmonic mean)** ì´ë¼ê³ ë„ í•©ë‹ˆë‹¤.
- ë¶„ë¥˜ í´ë˜ìŠ¤ê°„ **ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•  ë•Œ ì£¼ë¡œ ì‚¬ìš©**í•©ë‹ˆë‹¤.

```py
from sklearn.metrics import classification_report
classification_report(y_val, y_pred)
```

> ### ğŸ’¡ ì„ê³„ê°’(Threshold) ì¡°ì ˆ í•˜ê¸°
> ì„ê³„ê°’ì„ ì¡°ì ˆí•˜ë©´ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì„ ì„œë¡œ ê°•ì¡°ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
> ```py
> y_pred_proba = pipe.predict_proba(X_val)[:, 1]
> threshold = 0.5 # ì„ê³„ê°’ ì„¤ì •
> y_pred = y_pred_proba > threshold 
>
>ax = sns.histplot(y_pred_proba) # prob ì‹œê°í™”
>ax.axvline(threshold, color='red') # Threshold ì‹œê°í™”
>pd.Series(y_pred).value_counts() # False, True ê°’ ê³„ì‚°
>```

### ROC-ì»¤ë¸Œ, AUC
#### ROC-Curve
- **FPR(False Positive Rate)ê°€ ë³€í•  ë•Œ, TPR(True Positive Rate)ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€** ê³¡ì„ ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤. 
- FPR = 0 (ì„ê³„ê°’ì´ 1ë¡œ ì„¤ì •ëœ ê²½ìš°, ëª¨ë‘ ë¶€ì •ìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤.)
- FPR = 1 (ì„ê³„ê°’ì´ 0ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°, ëª¨ë‘ ê¸ì •ìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤.)

```py
from sklearn.metrics import roc_curve
fpr,tpr, thresholds = roc_curve(y_val, y_pred_proba) # y_true(íƒ€ê²Ÿê°’), y_score

roc = pd.DataFrame({
    'FPR(Fall-out)': fpr, # ìœ„ì–‘ì„±ë¥ 
    'TPRate(Recall)': tpr, # ì¬í˜„ìœ¨
    'Threshold': thresholds # ì„ê³„ê°’
})

# ROC ì»¤ë¸Œ ê·¸ë¦¬ê¸°
plt.scatter(fpr, tpr)
plt.title('ROC curve')
plt.xlabel('FPR(Fall-out)')
plt.ylabel('TPR(Recall)');

# ìµœì ì˜ ì„ê³„ê°’ ì°¾ê¸°
optimal_idx = np.argmax(tpr-fpr) # # threshold ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤, np.argmax()
optimal_threshold = thresholds[optimal_idx] # ìµœì ì˜ threshold ê°’
print('idx:', optimal_idx, ', threshold:', optimal_threshold)
# plt.plot(tpr-fpr);

# ì„ê³„ê°’ ê²°ê³¼ í™•ì¸í•˜ê¸°
y_pred_optimal = y_pred_proba >= optimal_threshold
print(classification_report(y_val, y_pred_optimal))
```

- [ğŸ”— ROC-Curve ê³µì‹ ë„íë¨¼íŠ¸](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)
- [ğŸ’» ROC ì»¤ë¸Œ ì§ì ‘ ì ìš©í•´ë³´ê¸° ](http://www.navan.name/roc/)

#### AUC
- AUCëŠ” **ROC ê³¡ì„ ì˜ ë„ˆë¹„**ë¥¼ ë§í•©ë‹ˆë‹¤. 
- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
- AUCê°€ ë†’ì„ ìˆ˜ë¡(ì™¼ìª½ ìœ„ ëª¨ì„œë¦¬ì— ê°€ê¹Œìš¸ ìˆ˜ë¡) ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¨ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.
- ì¦‰, ì´ ë§ì€ TPRì´ ë†’ê³  FPRì´ ë‚®ì„ìˆ˜ë¡ ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ë‚®ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ì˜ë‚˜ì˜¨ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```py
from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_val, y_pred_proba)
auc_score
```

[ğŸ”— auc ê³µì‹ ë„íë¨¼íŠ¸](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)

# Reference
- [ë¶„ë¥˜ / ì´ì§„ë¶„ë¥˜, ì„±ëŠ¥ì¸¡ì •, ë‹¤ì¤‘ë¶„ë¥˜ - Bo-lim.log](https://velog.io/@bo-lim/ë¶„ë¥˜-ì´ì§„ë¶„ë¥˜-ì„±ëŠ¥ì¸¡ì •-ë‹¤ì¤‘ë¶„ë¥˜)
- [[ML] ë¶„ë¥˜(Classification) - Data Repository](https://wannabenice.tistory.com/11)
- [ğŸ“¼ Introduction to the Confusion Matrix in Classification](https://youtu.be/wpp3VfzgNcI)
- [ğŸ“¼ Precision, Recall & F-Measure](https://www.youtube.com/watch?v=j-EB6RqqjGI)
- [ğŸ“¼ Making sense of the confusion matrix](https://www.youtube.com/watch?v=8Oog7TXHvFY)
- [ğŸ”— Classification metrics](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks#classification-metrics)