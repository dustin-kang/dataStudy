# 모델 평가
> 과대적합이나 과소적합이 발생했을 경우, 우리는 모델을 개선시키는 방법을 찾아야한다. 우선, 어떤 모델이 좋은 모델인지 확인하기 위헤 `편향-분산 트레이드 오프`를 통해 균형을 다룬다.

## 과대적합과 과소적합
### 과소적합(Underfitting)
> 모델이 **충분히 복잡하지 않아** 학습 데이터의 구조나 패턴을 정확히 반영하지 못하는 문제입니다.

- 그만큼 너무 단순해서 일반화 성질도 학습하지 못한 상태를 말합니다.
- 훈련 데이터와 테스트데이터의 오차가 너무 크게 나는 현상입니다.
- 모델의 제약을 줄이거나 파라미터가 더 복잡한 모델을 선택하여 이 문제를 해결합니다.

### 과대적합(Overfitting)
> 모델이 **학습 데이터에만 지나치게 최적화**하여 새로운 데이터에는 분류나 예측을 수행하지 못하는 문제입니다.

-  훈련 데이터에만 맞춰 있기 때문에 일반화가 안되는 상태를 말합니다.
- 테스트데이터에만 오차(loss)가 커지는 현상입니다.
- 훈련 데이터를 더 많이 모으거나 정규화, 정칙화, dropout등을 통해 적당히 복잡한 모델을 자동을 찾아 이 문제를 해결합니다.

### 일반화(Generalization)
>**훈련 데이터와 테스트 데이터가 비슷하게 좋은 성능**을 내는 경우를 말합니다.

><details><summary> <strong>🔍 정규화, 정칙화, 일반화 제대로 이해하기</strong> </summary>
> <strong>정규화(Normalization)</strong>는 데이터 단위를 맞추기 위해 0과 1사이 기준으로 맞춰 주는 것을 의미하고 <strong>정칙화(Regulalization;규제)</strong>는 과적합을 막기위해 일반화 시키는 방법을 의미합니다. 그리고 <strong>최적화(Optimization)</strong>는 훈련데이터로서 더 좋은 성능을 내기 위해 모델을 조정하는 것입니다. 즉, 일반화 지점까지 오기 위해 적절한 파라미터를 찾는 과정을 최적화라고 합니다.
</details>

## 분산 편향 트레이드오프(Bias & Variance Trade off)
> 모델이 과소적합이나 과대적합이 되었는지 알기 위해(탐지) 분산 편향 트레이드 오프를 사용합니다.


### 편향(Bias)
> 편향은 학습 알고리즘에서 **잘못된 가정으로 인한 오류**로 편향이 높으면 특성과 타깃의 관계를 잘 파악하지 못합니다.
- 데이터가 타깃으로부터 떨어져 있는 정도
- 훈련 데이터에서 오류 값이 크게 나는 경우 과소 적합이 발생합니다.

### 분산(Variance)
> **훈련 데이터셋의 변화에 민감성으로 발생하는 오차**로 분산이 높으면 학습 데이터의 노이즈가 민감하게 적합하여 테스트 데이터에서 일반화를 잘못하게 된다.
- 데이터 셋 내 데이터가 얼마나 퍼져 있는지를 나타내는 척도
- 훈련 세트와 테스트 세트의 오차가 크게 나는 경우 과대 적합이 발생합니다.


> 즉, 에러율을 가장 낮출 수 있는 지점까지만 학습 시켜면 되는 것입니다. 완벽하게 제거할 수 없으니 가장 적절한 지점을 찾으면 되는거죠.

[🔗 The Dangers of Under-fitting and Over-fitting - lsabella Lindgren](https://medium.com/analytics-vidhya/the-dangers-of-under-fitting-and-over-fitting-495f9efa1847)

# 모델 개선
## 하이퍼 파라미터 튜닝(Hyperparameter Tuning)
> 과대적합된 모델을 일반화된 지점까지 오게하기 위해 최적의 하이퍼 파라미터를 찾는 최적화(optimization) 과정이 필요합니다.(일명 ~~노가다 작업~~입니다.)

### 격자 검색(GridSearch)
- 검증하고 싶은 **하이퍼 파라미터들의 수치를 정해주고** 모두 검정합니다.
- 모든 매개변수 값들의 조합으로 평가하여 최적의 선택을 결정합니다.
- 하지만, 그만큼 많은 조합이 있으면 많은 시간을 소비한다는 문제점이 있습니다.

```py
from sklearn.model_selection import  GridSearchCV

param_grid = {
    'max_depth' : [None, 1, 2, 3, 4],
    'max_leaf_nodes' : [3, 5, 7, 9]
}

grid_search = GridSearchCV(Model, param_grid=param_grid, scoring='accuary', cv=5, n_jobs=1)
grid_search.fit(X_train, y_train)

df = pd.DataFrame(grid_search.cv_results_)
```
- `estimator` : 모델 객체 생성
- `param_grid` : 하이퍼 파라미터 목록을 `Dictionary` 형태로 전달 (파라미터 값은 `List`)
-  `scoring` : 평가 지표를 나타내며, 여러 개일 경우, `list`로 묶어 지정한다.
-  `refit` : 최적의 파라미터를 정할 때 사용하는 평가지표로 여러 개의 평가지표를 설정한 경우 반드시 설정한다.
-  `cv` : 교차 검증 시, fold 갯수
-  `n_jobs` L 사용할 CPU 코어 갯수 (None:1(default), -1: 모든 코어)

> `Sklearn`의 `GridSearchCV` 함수는 전처리 과정에서 효과적으로 반영하기 어렵기 떄문에 `sklearn.model_selection.ParameterGrid`라는 함수를 사용하기도 합니다.  [🔗 모델 성능 향상을 위한 하이퍼 파라미터 튜닝 - GIL'S LAB](https://gils-lab.tistory.com/10)

[🔗 GridSearch 공식문서](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)
### 랜덤 검색(RandonizedSearch)
- 검증하고 싶은 **하이퍼 파라미터들의 범위를 지정**하고 **무작위로 지정**해 검정한다.

```py
from sklearn.model_selection import RandomizedSearchCV

param_drstributuions = {
    'max_depth' : range(1, 11),
    'max_leaf_nodes' : range(3, 31, 3)
}

grid_search = GridSearchCV(Model, param_drstributuions=param_drstributuions, n_iter=60, cv=5, n_jobs=1)
grid_search.fit(X_train, y_train)
```
- `estimator` : 모델 객체 생성
- `param_grid` : 하이퍼 파라미터 목록을 `Dictionary` 형태로 전달 (파라미터 값은 `List`)
-  `scoring` : 평가 지표를 나타내며, 여러 개일 경우, `list`로 묶어 지정한다.
-  `n_iter` : 파라미터 검색 횟수 (정해진 분포 내에서 무작위로 샘플링)
-  `refit` : 최적의 파라미터를 정할 때 사용하는 평가지표로 여러 개의 평가지표를 설정한 경우 반드시 설정한다.
-  `cv` : 교차 검증 시, fold 갯수
-  `n_jobs` L 사용할 CPU 코어 갯수 (None:1(default), -1: 모든 코어)

### 훈련 결과 도출
- `predict_proba(x)` : 분류문제에서 class별 확률을 반환한다.
- `cv_results_` : 파라미터 조합 별 평가 결과를 딕셔너리로 반환한다.
- `best_params_` : 가장 좋은 성능을 낸 파라미터 조합을 반환한다.
- `best_estimators_`: 가장 좋은 성능을 낸 모델 반환한다.
- `best_score_`: 가장 좋은 점수를 반환한다.
- `rank_test_score` : 테스트 순위
- `mean_score_time` : 예측에 걸리는 시간
- `split{n}_test_score` : 교차 검증 결과

[🔗 [DL] Hyperparameter Search - Daikoku](https://m.blog.naver.com/jjys9047/222066330831)
[🔗 RandomizedSearch 공식문서](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)<br> [💻 실습 파일 바로가기](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)
