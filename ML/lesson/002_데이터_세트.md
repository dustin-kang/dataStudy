# 데이터 정리
## 정형데이터와 비정형 데이터
- **정형 데이터(Structured Data)** : 미리 정해놓은 형식과 구조가 있는 구조화된 데이터
- **비정형 데이터(Semi-Structured Data)**: 사진이나 문자, 음성과 같이 컴퓨터가 이해할 수 없는 구조의 데이터
- **반정형 데이터(Unstructured Data)**: 데이터의 구조 정보를 데이터와 함께 제공하는 파일 _eg. XML, HTML, JSON_

## 데이터 세트
### 데이터를 선별하는 규칙
1. 전혀 상관없는 데이터는 버려라. _ex) 서울 날씨를 알기위해 부산 날씨 데이터를 가져오는 경우_
2. 라벨링이 잘못된 데이터는 가져오지 말라. _ex) Out-lier_

### 데이터 세트

<img src="https://user-images.githubusercontent.com/55238671/209548942-07d9e3f5-132c-4834-9acf-2bcc3e3492a7.png">


> <details> <summary> 🔍 전체 데이터세트로 평가를 진행하게 되면? </summary>
> 성능이 잘 나올 수 밖에 없습니다. 훈련 데이터와 검증 데이터를 분리하지 않고 학습을 하게되면 Data Leakage 가 발생하여 과적합으로 성능을 떨어트리게 됩니다.
> </detail>

- **학습 데이터 (Training Data)**
모델이 학습할 때 사용하는 데이터로 모델의 성능을 좌우한다.

- **검증 데이터 (Validation Data)**
  - 모델의 성능을 검증할 때 사용하는 데이터로, 성능을 높일 때 까지 반복한다.
  - 예비 테스트 데이터라고 생각하면 된다.
  - 교차 검증할때에도 쓰인다.

- **테스트 데이터(Test Data)**
앞 결과(학습, 검증)에 만족스러웠다면 최종적으로 테스트를 위해 사용하는 데이터이다.

> **📌 데이터 세트 규칙**
> - 훈련 데이터 세트는 테스트 데이터 세트보다 많아야 한다.
> - 두 세트간에 중복 데이터가 최대한 없어야 한다.
> - 두 세트의 타깃 클래스 비율 분포가 동일해야 한다.

### 💻 `train_test_split(X_data, Y_data)`
- `test_size` : 테스트 데이터 세트의 비율을 의미한다. 
- `random_state` : 수행시 마다 동일한 결과를 얻기 위해 적용하는 인자 (랜덤 값 고정)
- `shuffle` : 데이터를 나누기 전에 섞을지에 대한 불린 여부
- `stratify` : 분류 문제에서 중요하게 다루는 파라미터로 target의 클래스 비율을 유지한채 나눌 수 있다.

```py
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)

```

- [🔗 scikit-learn 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [🔗 How (and why) to create a good validation set
](https://www.fast.ai/posts/2017-11-13-validation-sets.html)