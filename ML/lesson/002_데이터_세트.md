# 데이터 정리
## 정형데이터와 비정형 데이터
- **정형 데이터(Structured Data)** : 미리 정해놓은 형식과 구조가 있는 구조화된 데이터
- **비정형 데이터(Semi-Structured Data)**: 사진이나 문자, 음성과 같이 컴퓨터가 이해할 수 없는 구조의 데이터
- **반정형 데이터(Unstructured Data)**: 데이터의 구조 정보를 데이터와 함께 제공하는 파일 _eg. XML, HTML, JSON_

## 데이터 세트
### 데이터를 선별하는 규칙
1. 전혀 상관없는 데이터는 버려라. _ex) 서울 날씨를 알기위해 부산 날씨 데이터를 가져오는 경우_
2. 라벨링이 잘못된 데이터는 가져오지 말라. _ex) Out-lier_

### 데이터 세트

<img src="https://user-images.githubusercontent.com/55238671/209548942-07d9e3f5-132c-4834-9acf-2bcc3e3492a7.png">


> <details> <summary> 🔍 전체 데이터세트로 평가를 진행하게 되면? </summary>
> 성능이 잘 나올 수 밖에 없습니다. 훈련 데이터와 검증 데이터를 분리하지 않고 학습을 하게되면 Data Leakage 가 발생하여 과적합으로 성능을 떨어트리게 됩니다.
> </detail>

- **학습 데이터 (Training Data)**
모델이 학습할 때 사용하는 데이터로 모델의 성능을 좌우한다.

- **검증 데이터 (Validation Data)**
  - **모델의 성능을 평가하기 위해** 사용하는 데이터로, 성능을 높일 때 까지 반복한다.
  - 예비 테스트 데이터라고 생각하면 된다.
  - 교차 검증할때에도 쓰인다.

- **테스트 데이터(Test Data)**
앞 결과(학습, 검증)에 만족스러웠다면 최종적으로 테스트를 위해 사용하는 데이터이다.

> **📌 데이터 세트 규칙**
> - 훈련 데이터 세트는 테스트 데이터 세트보다 많아야 한다.
> - 두 세트간에 중복 데이터가 최대한 없어야 한다.
> - 두 세트의 타깃 클래스 비율 분포가 동일해야 한다.

## 훈련곡선과 검증 곡선(Validation Curve)
> 하이퍼 파라미터에 대한 훈련, 검증 스코어를 확인할 수 있습니다.

<img width="682" alt="image" src="https://user-images.githubusercontent.com/55238671/210363176-980fe0dc-5cb4-46db-b8dc-ca75880213c2.png">


### 학습곡선
> 학습 데이터의 양을 늘리면서 모델의 성능을 평가하는 그래프
> - X(훈련 데이터수),Y(정확도)

```py
from matplotlib import pyplot as plt
from sklearn.model_selection import learning_curve

# 학습 곡선 만들기
train_sizes, train_scores, test_scores = learning_curve(estimator=모델, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=반복수)

# 학습 곡선 그리기
## 학습 정확도
plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')
plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')
## 검증 정확도
plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')
plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')

## 그리드 외 라벨
plt.grid()
plt.xlabel('Number of training samples')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()
```
- `train_sizes` : 학습 곡선 생성에 필요하 훈랜 샘플과 개수 비율을 조절합니다.

### 검증곡선
> 하이퍼 파라미터에 따라 과대, 과소 적합 여부를 판단하는 그래프
> > - X(하이퍼 파라미터 C),Y(정확도)

```py
from matplotlib import pyplot as plt
from sklearn.model_selection import validation_curve

# 검증 곡선 만들기
train_scores, test_scores = validation_curve(estimator=모델, X=X_train, y=y_train, param_name='C', param_range=param_range, cv=10)

# 검증 곡선 그리기
## 학습 정확도
plt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')
plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')
## 검증 정확도
plt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')
plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')

## 그리드 외 라벨
plt.grid()
plt.xscale('log')
plt.legend(loc='lower right')
plt.xlabel('Param C') # 하이퍼 파라미터 C
plt.ylabel('Accuracy')
plt.tight_layout()
plt.show()
```
- `param_range`에서는 이름처럼 값 범위를 지정해줍니다.

> 규제 강도를 높여 C를 줄이면 조금 과소적합되고, 규제 강도를 낮춰 C를 늘리면 조금 과대적합됨을 확인할 수 있습니다.

[🔗 사이킷런 학습 곡선, 검증 곡선으로 모델의 과대적합, 과소적합 조사하기 - jellyho](https://jellyho.com/blog/85/)
[🔗 `learning_curve` 사이킷런 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html)
[🔗 `validation_curve` 사이킷런 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn-model-selection-validation-curve)
### 💻 `train_test_split(X_data, Y_data)`
- `test_size` : 테스트 데이터 세트의 비율을 의미한다. 
- `random_state` : 수행시 마다 동일한 결과를 얻기 위해 적용하는 인자 (랜덤 값 고정)
- `shuffle` : 데이터를 나누기 전에 섞을지에 대한 불린 여부
- `stratify` : 분류 문제에서 중요하게 다루는 파라미터로 target의 클래스 비율을 유지한채 나눌 수 있다.

```py
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)

```

- 데이터가 많은 경우 : 훈련 / 검증 / 테스트 데이터 셋으로 나눈다. (**Hold-Out 검증**)
- 데이터가 적은 경우 : **[K-fold 교차검증(k-fold cross validation)](https://github.com/dustin-kang/dataStudy/blob/main/ML/lesson/006_모델_선택과_모델_검증.md#k-겹-교차검증k-fold-cross-validation)**을 진행한다.

- [🔗 scikit-learn 공식 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [🔗 How (and why) to create a good validation set
](https://www.fast.ai/posts/2017-11-13-validation-sets.html)
